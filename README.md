# ML_MultipleRegression
## degree的多項式回歸和訓練樣本數N的關係

> 利用(直線方程式、三次/六次/九次/十二次方程式)擬合數據點
     ![avatar](D:/1.png)

> 使用函數 mean_squared_error(MSE)來計算誤差以及截距

> 輸出標準正態分佈的矩陣並用散佈圖畫出

> 利用(直線方程式、三次/六次/九次/十二次方程式)擬合數據點

> 並print出訓練樣本數(n=10、n=50、n=100)時，方程式擬合狀況。

## 結論
*從不同degree的多項式迴歸可以看出不同迴歸係數、截距以及殘差，從數據與圖形可以看出，而在直線迴歸的殘差高達0.25，但是隨著方程式的degree增加，可以從圖看出   方程式越來越擬合樣本數。

*這些曲線與我們最開始數據的來源（一個二次方程加上一些隨機變量）差異非常大。如果從相同來源再取一些樣本數，使用該模型預測會出現非常大的誤差，可能出現過擬   合狀況，可以透過降低模型複雜度(漸少degree)、降維(減少特徵數量)、增加訓練樣本以及添加正則化項，來防止模型過擬合。

